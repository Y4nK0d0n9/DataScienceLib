## 机器学习的一般流程

### 数据收集

### ETL
确定数据收集范围

### 数据读取

### 数据格式转换

### EDA

### 数据清洗
#### 缺失值处理
#### 样本均衡
#### 异常值处理

* 高斯
* OneCLassSVM
* KNN

### 特征工程

#### 特征选择

* 通过卡方检验移除低方差特征
* 构建单特征预选模型根据准确度排序，选择前K个特征
* 对每个特征通过计算与预测变的person或互信息系数计算相关性进行选择
* 距离相关系数如果是0则两个变量独立
* 递归式特征消除:根据训练模型的coef_属性选出最好的然后用剩下的训练再选出最好的
* 训练能够对特征打分的预选模型，根据训练模型的coef_属性与阈值筛选特征
* L1正则得到稀疏矩阵，基于L1的模型会得到系数解可以去掉这些系数为0的特征
* 基于L2有关联的特征选择:表示能力强的特征对应的系数是非零，若一个特征在L1中的权值为1，选择在L2中权值差别不大且在L1中权值为0的特征构成同类集合，将这一集合中的特征平分L1中的权值
* 组合特征提高模型的非线性能力
* 构建深度学习模型选择某一层作为特征
* 稳定性选择:在不同特征子集上运行特征选择算法统计某个特征被认为是重要特征的频率

#### 离散特征编码
#### 连续特征
##### 标准化
##### 归一化

### 降维
#### SVD
#### PCA

### 生成训练集

### 模型选择
#### LR
##### 优点
##### 缺点
##### 数据要求
##### 场景

#### FTRL
#### FTML
#### FFM
#### GBDT
##### 优点
##### 缺点
##### 数据要求
##### 场景

#### DNN
#### Wide&Deep

### 求参策略(LOSS)
#### MSE
#### MLE
#### 交叉熵
#### 平方损失

### 求参算法
#### GD
#### SGD
#### Monentum
#### Adagrad
#### Adam

### 模型调试
#### 参数调整
#### 错误分析

### 模型集成
#### Bagging
#### Boosting
#### Stacking

### 生成测试集

### 模型评估

### 数据更新

### 模型更新

## 一些例子
